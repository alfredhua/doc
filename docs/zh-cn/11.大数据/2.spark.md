

## **Local** 模式

- 启动 **Local** 环境

- 进入解压缩后的路径，执行如下指令

  ```shell
  bin/spark-shell
  ```

  ![image](https://java-run-blog.oss-cn-zhangjiakou.aliyuncs.com/blog/LmUnzh.png)



## **Standalone** 模式

local 本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的 集群中去执行，这里我们来看看只使用 Spark 自身节点运行的集群模式，也就是我们所谓的 独立部署(Standalone)模式。Spark 的 Standalone 模式体现了经典的 master-slave 模式。 集群规划:

| master        | worker | worker |
| ------------- | ------ | ------ |
| worker master | worker | worker |



**每台机器都需要修改**

- 修改配置文件

  进入解压缩后路径的 conf 目录，修改 workers.template 文件名为 workers.

  1. 修改 works 文件，添加 work 节点

  centos01

  centos02

  centos03

  

- 修改 spark-env.sh.template 文件名为 spark-env.sh

```
mv spark-env.sh.template spark-env.sh
```

- 修改 spark-env.sh 文件，添加 JAVA_HOME 环境变量和集群对应的 master 节点

```shell
export JAVA_HOME=/opt/module/jdk1.8.0_144
SPARK_MASTER_HOST=centos
SPARK_MASTER_PORT=7077
```

- 执行命令

  sbin/start-all.sh

![images](https://java-run-blog.oss-cn-zhangjiakou.aliyuncs.com/blog/FzN1X1.png)

- 执行命令验证

  ```shell
  bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://centos01:7077 ./examples/jars/spark-examples_2.12-3.1.2.jar 10
  ```

  

## 配置高可用(**HA**)

所谓的高可用是因为当前集群中的 Master 节点只有一个，所以会存在单点故障问题。所以为了解决单点故障问题，需要在集群中配置多个 Master 节点，一旦处于活动状态的 Master 发生故障时，由备用 Master 提供服务，保证作业可以继续执行。这里的高可用一般采用 Zookeeper 设置。

| centos01                | centos02                | centos03         |
| ----------------------- | ----------------------- | ---------------- |
| Master worker zookeeper | Master worker zookeeper | worker zookeeper |

- 修改 spark-env.sh 文件添加如下配置

```shell
注释如下内容:
#SPARK_MASTER_HOST=linux1
#SPARK_MASTER_PORT=7077
添加如下内容:
#Master 监控页面默认访问端口为 8080，但是可能会和 Zookeeper 冲突，所以改成 8989，也可以自 定义，访问 UI 监控页面时请注意
SPARK_MASTER_WEBUI_PORT=8989
export SPARK_DAEMON_JAVA_OPTS="

-Dspark.deploy.recoveryMode=ZOOKEEPER
-Dspark.deploy.zookeeper.url=centos01,centos02,centos03
-Dspark.deploy.zookeeper.dir=/spark"
```

- 启动集群

  ```shell
  sbin/start-all.sh
  ```

  

## **Yarn** 模式

独立部署(Standalone)模式由 Spark 自身提供计算资源，无需其他框架提供资源。这 种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark 主 要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是 和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的 Yarn 环境 下 Spark 是如何工作的(其实是因为在国内工作中，Yarn 使用的非常多)。

- 修改配置文件

  ```shell
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  YARN_CONF_DIR=/opt/module/hadoop/etc/hadoop
  ```

  
