{
  "filename": "2.spark.md",
  "__html": "<h2 id=\"local-%E6%A8%A1%E5%BC%8F\"><strong>Local</strong> 模式 <a class=\"header-anchor\" href=\"#local-%E6%A8%A1%E5%BC%8F\">#</a></h2>\n<ul>\n<li>\n<p>启动 <strong>Local</strong> 环境</p>\n</li>\n<li>\n<p>进入解压缩后的路径，执行如下指令</p>\n<pre><code class=\"language-shell\">bin/spark-shell\n</code></pre>\n<p><img src=\"https://java-run-blog.oss-cn-zhangjiakou.aliyuncs.com/blog/LmUnzh.png\" alt=\"image\"></p>\n</li>\n</ul>\n<h2 id=\"standalone-%E6%A8%A1%E5%BC%8F\"><strong>Standalone</strong> 模式 <a class=\"header-anchor\" href=\"#standalone-%E6%A8%A1%E5%BC%8F\">#</a></h2>\n<p>local 本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的 集群中去执行，这里我们来看看只使用 Spark 自身节点运行的集群模式，也就是我们所谓的 独立部署(Standalone)模式。Spark 的 Standalone 模式体现了经典的 master-slave 模式。 集群规划:</p>\n<table>\n<thead>\n<tr>\n<th>master</th>\n<th>worker</th>\n<th>worker</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>worker master</td>\n<td>worker</td>\n<td>worker</td>\n</tr>\n</tbody>\n</table>\n<p><strong>每台机器都需要修改</strong></p>\n<ul>\n<li>\n<p>修改配置文件</p>\n<p>进入解压缩后路径的 conf 目录，修改 workers.template 文件名为 workers.</p>\n<ol>\n<li>修改 works 文件，添加 work 节点</li>\n</ol>\n<p>centos01</p>\n<p>centos02</p>\n<p>centos03</p>\n</li>\n<li>\n<p>修改 spark-env.sh.template 文件名为 <a href=\"http://spark-env.sh\">spark-env.sh</a></p>\n</li>\n</ul>\n<pre><code>mv spark-env.sh.template spark-env.sh\n</code></pre>\n<ul>\n<li>修改 <a href=\"http://spark-env.sh\">spark-env.sh</a> 文件，添加 JAVA_HOME 环境变量和集群对应的 master 节点</li>\n</ul>\n<pre><code class=\"language-shell\">export JAVA_HOME=/opt/module/jdk1.8.0_144\nSPARK_MASTER_HOST=centos\nSPARK_MASTER_PORT=7077\n</code></pre>\n<ul>\n<li>\n<p>执行命令</p>\n<p>sbin/start-all.sh</p>\n</li>\n</ul>\n<p><img src=\"https://java-run-blog.oss-cn-zhangjiakou.aliyuncs.com/blog/FzN1X1.png\" alt=\"images\"></p>\n<ul>\n<li>\n<p>执行命令验证</p>\n<pre><code class=\"language-shell\">bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://centos01:7077 ./examples/jars/spark-examples_2.12-3.1.2.jar 10\n</code></pre>\n</li>\n</ul>\n<h2 id=\"%E9%85%8D%E7%BD%AE%E9%AB%98%E5%8F%AF%E7%94%A8(ha)\">配置高可用(<strong>HA</strong>) <a class=\"header-anchor\" href=\"#%E9%85%8D%E7%BD%AE%E9%AB%98%E5%8F%AF%E7%94%A8(ha)\">#</a></h2>\n<p>所谓的高可用是因为当前集群中的 Master 节点只有一个，所以会存在单点故障问题。所以为了解决单点故障问题，需要在集群中配置多个 Master 节点，一旦处于活动状态的 Master 发生故障时，由备用 Master 提供服务，保证作业可以继续执行。这里的高可用一般采用 Zookeeper 设置。</p>\n<table>\n<thead>\n<tr>\n<th>centos01</th>\n<th>centos02</th>\n<th>centos03</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Master worker zookeeper</td>\n<td>Master worker zookeeper</td>\n<td>worker zookeeper</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>修改 <a href=\"http://spark-env.sh\">spark-env.sh</a> 文件添加如下配置</li>\n</ul>\n<pre><code class=\"language-shell\">注释如下内容:\n<span class=\"hljs-meta\">#</span><span class=\"bash\">SPARK_MASTER_HOST=linux1</span>\n<span class=\"hljs-meta\">#</span><span class=\"bash\">SPARK_MASTER_PORT=7077</span>\n添加如下内容:\n<span class=\"hljs-meta\">#</span><span class=\"bash\">Master 监控页面默认访问端口为 8080，但是可能会和 Zookeeper 冲突，所以改成 8989，也可以自 定义，访问 UI 监控页面时请注意</span>\nSPARK_MASTER_WEBUI_PORT=8989\nexport SPARK_DAEMON_JAVA_OPTS=\"\n\n-Dspark.deploy.recoveryMode=ZOOKEEPER\n-Dspark.deploy.zookeeper.url=centos01,centos02,centos03\n-Dspark.deploy.zookeeper.dir=/spark\"\n</code></pre>\n<ul>\n<li>\n<p>启动集群</p>\n<pre><code class=\"language-shell\">sbin/start-all.sh\n</code></pre>\n</li>\n</ul>\n<h2 id=\"yarn-%E6%A8%A1%E5%BC%8F\"><strong>Yarn</strong> 模式 <a class=\"header-anchor\" href=\"#yarn-%E6%A8%A1%E5%BC%8F\">#</a></h2>\n<p>独立部署(Standalone)模式由 Spark 自身提供计算资源，无需其他框架提供资源。这 种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark 主 要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是 和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的 Yarn 环境 下 Spark 是如何工作的(其实是因为在国内工作中，Yarn 使用的非常多)。</p>\n<ul>\n<li>\n<p>修改配置文件</p>\n<pre><code class=\"language-shell\">export JAVA_HOME=/opt/module/jdk1.8.0_144\nYARN_CONF_DIR=/opt/module/hadoop/etc/hadoop\n</code></pre>\n</li>\n</ul>\n",
  "link": "/zh-cn/docs/11.大数据/2.spark.html",
  "meta": {}
}