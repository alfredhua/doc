{
  "filename": "2.kafka.md",
  "__html": "<h2 id=\"%E4%BB%80%E4%B9%88%E6%98%AFkafka\">什么是kafka <a class=\"header-anchor\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFkafka\">#</a></h2>\n<blockquote>\n<p>Apache Kafka是一个分布式发布 - 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。</p>\n</blockquote>\n<h3 id=\"%E5%A5%BD%E5%A4%84\">好处 <a class=\"header-anchor\" href=\"#%E5%A5%BD%E5%A4%84\">#</a></h3>\n<p>以下是Kafka的几个好处 -</p>\n<ul>\n<li><strong>可靠性</strong> - Kafka是分布式，分区，复制和容错的。</li>\n<li><strong>可扩展性</strong> - Kafka消息传递系统轻松缩放，无需停机。</li>\n<li><strong>耐用性</strong> - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。</li>\n<li><strong>性能</strong> - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。</li>\n</ul>\n<p>Kafka非常快，并保证零停机和零数据丢失。</p>\n<h3 id=\"%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF\">应用场景 <a class=\"header-anchor\" href=\"#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF\">#</a></h3>\n<ul>\n<li><strong>指标</strong> - Kafka通常用于操作监控数据。 这涉及聚合来自分布式应用程序的统计信息，以产生操作数据的集中馈送。</li>\n<li><strong>日志聚合解决方案</strong> - Kafka可用于跨组织从多个服务收集日志，并使它们以标准格式提供给多个服务器。</li>\n<li><strong>流处理</strong> - 流行的框架(如Storm和Spark Streaming)从主题中读取数据，对其进行处理，并将处理后的数据写入新主题，供用户和应用程序使用。 Kafka的强耐久性在流处理的上下文中也非常有用。</li>\n</ul>\n<h2 id=\"kafka%E7%89%B9%E7%82%B9\">kafka特点 <a class=\"header-anchor\" href=\"#kafka%E7%89%B9%E7%82%B9\">#</a></h2>\n<ul>\n<li>kafka 是一个基于发布-订阅的分布式消息系统（消息队列）</li>\n<li>Kafka 面向大数据，消息保存在主题中，而每个 topic 有分为多个分区</li>\n<li>kafak 的消息数据保存在磁盘，每个 partition 对应磁盘上的一个文件，消息写入就是简单的文件追加，文件可以在集群内复制备份以防丢失</li>\n<li>即使消息被消费，kafka 也不会立即删除该消息，可以通过配置使得过一段时间后自动删除以释放磁盘空间</li>\n<li>kafka依赖分布式协调服务Zookeeper，适合离线/在线信息的消费，与 storm 和 spark 等实时流式数据分析常常结合使用</li>\n</ul>\n<h2 id=\"kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA%E5%91%A2%EF%BC%9F\">Kafka为什么要进行分区呢？ <a class=\"header-anchor\" href=\"#kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA%E5%91%A2%EF%BC%9F\">#</a></h2>\n<p>最根本的原因就是：kafka基于文件进行存储，任何发布到此 partition 的消息都会被直接追加到 log 文件的尾部，当文件内容大到一定程度时，很容易达到单个磁盘的上限，因此，采用分区的办法，一个分区对应一个文件，这样就可以将数据分别存储到不同的server上去，另外这样做也可以负载均衡，容纳更多的消费者。</p>\n<h2 id=\"%E4%B8%BA%E4%BB%80%E4%B9%88kafka%E4%B8%AD%E4%B8%8D%E5%85%81%E8%AE%B8%E5%AF%B9%E6%B6%88%E6%81%AF%E8%BF%9B%E8%A1%8C%E2%80%9C%E9%9A%8F%E6%9C%BA%E8%AF%BB%E5%86%99%E2%80%9D\">为什么kafka中不允许对消息进行“随机读写” <a class=\"header-anchor\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88kafka%E4%B8%AD%E4%B8%8D%E5%85%81%E8%AE%B8%E5%AF%B9%E6%B6%88%E6%81%AF%E8%BF%9B%E8%A1%8C%E2%80%9C%E9%9A%8F%E6%9C%BA%E8%AF%BB%E5%86%99%E2%80%9D\">#</a></h2>\n<p>一个分区对应一个磁盘上的文件，而消息在文件中的位置就称为 offset（偏移量），offset 为一个 long 型数字，它可以唯一标记一条消息。由于kafka 并没有提供其他额外的索引机制来存储 offset，文件只能顺序的读写，所以在kafka中几乎不允许对消息进行“随机读写”。</p>\n<h2 id=\"%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E8%BF%87%E7%A8%8B\">数据生产过程 <a class=\"header-anchor\" href=\"#%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E8%BF%87%E7%A8%8B\">#</a></h2>\n<p>对于生产者要写入的一条记录，可以指定四个参数：分别是 topic、partition、key 和 value，其中 topic 和 value（要写入的数据）是必须要指定的，而 key 和 partition 是可选的。</p>\n<p>对于一条记录，先对其进行序列化，然后按照 Topic 和 Partition，放进对应的发送队列中。如果 Partition 没填，那么情况会是这样的：a、Key 有填。按照 Key 进行哈希，相同 Key 去一个 Partition。b、Key 没填。Round-Robin 来选 Partition。</p>\n<p>producer 将会和Topic下所有 partition leader 保持 socket 连接，消息由 producer 直接通过 socket 发送到 broker。其中 partition leader 的位置( host : port )注册在 zookeeper 中，producer 作为 zookeeper client，已经注册了 watch 用来监听 partition leader 的变更事件，因此，可以准确的知道谁是当前的 leader。</p>\n<p>producer 端采用异步发送：将多条消息暂且在客户端 buffer 起来，并将他们批量的发送到 broker，小数据 IO 太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。</p>\n<h2 id=\"%E6%95%B0%E6%8D%AE%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B\">数据消费过程 <a class=\"header-anchor\" href=\"#%E6%95%B0%E6%8D%AE%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B\">#</a></h2>\n<p>对于消费者，不是以单独的形式存在的，每一个消费者属于一个 consumer group，一个 group 包含多个 consumer。特别需要注意的是：订阅 Topic 是以一个消费组来订阅的，发送到 Topic 的消息，只会被订阅此 Topic 的每个 group 中的一个 consumer 消费。</p>\n<p>如果所有的 Consumer 都具有相同的 group，那么就像是一个点对点的消息系统；如果每个 consumer 都具有不同的 group，那么消息会广播给所有的消费者。</p>\n<p>具体说来，这实际上是根据 partition 来分的，一个 Partition，只能被消费组里的一个消费者消费，但是可以同时被多个消费组消费，消费组里的每个消费者是关联到一个 partition 的，因此有这样的说法：对于一个 topic,同一个 group 中不能有多于 partitions 个数的 consumer 同时消费,否则将意味着某些 consumer 将无法得到消息。</p>\n<p>同一个消费组的两个消费者不会同时消费一个 partition。</p>\n<p>在 kafka 中，采用了 pull 方式，即 consumer 在和 broker 建立连接之后，主动去 pull(或者说 fetch )消息，首先 consumer 端可以根据自己的消费能力适时的去 fetch 消息并处理，且可以控制消息消费的进度(offset)。</p>\n<p>partition 中的消息只有一个 consumer 在消费，且不存在消息状态的控制，也没有复杂的消息确认机制，可见 kafka broker 端是相当轻量级的。当消息被 consumer 接收之后，需要保存 Offset 记录消费到哪，以前保存在 ZK 中，由于 ZK 的写性能不好，以前的解决方法都是 Consumer 每隔一分钟上报一次，在 0.10 版本后，Kafka 把这个 Offset 的保存，从 ZK 中剥离，保存在一个名叫 consumeroffsets topic 的 Topic 中，由此可见，consumer 客户端也很轻量级</p>\n<h2 id=\"kafka%E4%BC%A0%E9%80%81%E6%9C%BA%E5%88%B6\">kafka传送机制 <a class=\"header-anchor\" href=\"#kafka%E4%BC%A0%E9%80%81%E6%9C%BA%E5%88%B6\">#</a></h2>\n<p>Kafka 支持 3 种消息投递语义,在业务中，常常都是使用 At least once 的模型。</p>\n<ul>\n<li>At most once：最多一次，消息可能会丢失，但不会重复。</li>\n<li>At least once：最少一次，消息不会丢失，可能会重复。</li>\n<li>Exactly once：只且一次，消息不丢失不重复，只且消费一次。</li>\n</ul>\n",
  "link": "/zh-cn/docs/4.mq/kafka/2.kafka.html",
  "meta": {}
}