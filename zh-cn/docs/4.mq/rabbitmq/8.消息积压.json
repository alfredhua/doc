{
  "filename": "8.消息积压.md",
  "__html": "<h1 id=\"%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B\">生产消息积压 <a class=\"header-anchor\" href=\"#%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B\">#</a></h1>\n<p>解决思路：</p>\n<ol>\n<li>先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉</li>\n<li>新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量</li>\n<li>然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue</li>\n<li>接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据</li>\n<li>这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据</li>\n<li>等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息。</li>\n</ol>\n<p>消息队列满了如何处理？</p>\n<p>如果走的方式是消息积压在mq里，那么如果你很长时间都没处理掉，此时导致mq都快写满了，咋办？\n这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，再补数据吧。</p>\n",
  "link": "/zh-cn/docs/4.mq/rabbitmq/8.消息积压.html",
  "meta": {}
}